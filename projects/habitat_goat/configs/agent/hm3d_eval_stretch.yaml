BASE_TASK_CONFIG_PATH: configs/task/hm3d_challenge2022_val.yaml

NO_GPU: 0                 # 1: ignore IDs above and run on CPU, 0: run on GPUs with IDs above
NUM_ENVIRONMENTS: 35      # number of environments (per agent process)
DUMP_LOCATION: datadump   # path to dump models and log
EXP_NAME: stretch_openvocab_   # experiment name
VISUALIZE: 0              # 1: render observation and predicted semantic map, 0: no visualization
PRINT_IMAGES: 1           # 1: save visualization as images, 0: no image saving
GROUND_TRUTH_SEMANTICS: 1 # 1: use ground-truth semantics (for debugging / ablations)
seed: 1
SHOW_RL_OBS: False         # whether to show the observations passed to RL policices, for debugging

ENVIRONMENT:
  turn_angle: 30.0        # agent turn angle (in degrees)
  frame_height: 640       # first-person frame height (in pixels)
  frame_width: 360        # first-person frame width (in pixels)
  camera_height: 1.31     # camera sensor height (in metres)
  hfov: 42              # horizontal field of view (in degrees)
  min_depth: 0.5          # minimum depth for depth sensor (in metres)
  max_depth: 5.0          # maximum depth for depth sensor (in metres)
  max_num_sub_task_episodes: 5

AGENT:
  max_steps: 500          # maximum number of steps before stopping an episode
  panorama_start: 1       # 1: turn around 360 degrees when starting an episode, 0: don't
  exploration_strategy: seen_frontier  # exploration strategy ("seen_frontier", "been_close_to_frontier")
  radius: 0.05            # robot radius (in meters)
  store_all_categories: True  # whether to store all semantic categories in the map or just task-relevant ones

  SEMANTIC_MAP:
    semantic_categories: langnav_cat # map semantic channel categories ("coco_indoor", "longtail_indoor", "mukul_indoor")
    num_sem_categories: 380           # number of map semantic channel categories (16, 257, 35)
    map_size_cm: 4800        # global map size (in centimeters)
    map_resolution: 5        # size of map bins (in centimeters)
    vision_range: 100        # diameter of local map region visible by the agent (in cells)
    global_downscaling: 2    # ratio of global over local map
    du_scale: 4              # frame downscaling before projecting to point cloud
    cat_pred_threshold: 1.0  # number of depth points to be in bin to classify it as a certain semantic category
    exp_pred_threshold: 1.0  # number of depth points to be in bin to consider it as explored
    map_pred_threshold: 1.0  # number of depth points to be in bin to consider it as obstacle
    explored_radius: 150     # radius (in centimeters) of visually explored region
    been_close_to_radius: 100  # radius (in centimeters) of been close to region
    target_blacklisting_radius: 100 # radius (in centimeters) of region around goal to blacklist if object isn't a valid target
    must_explore_close: False
    min_obs_height_cm: 10    # minimum height (in centimeters) of obstacle to be considered as obstacle
    # erosion and filtering to reduce the number of spurious artifacts
    dilate_obstacles: True
    dilate_size: 3
    dilate_iter: 1
    exploration_type: 'default'
    max_depth: 5.0 # hacky (for goat agent module)

    depth_filtering: True
    depth_filter_range_cm: 100        # 1m about the depth median (+/- 50cm)
    preprojection_kp_dilation: 15 
    goal_filtering: True

    record_instance_ids: True  # whether to predict and store instance ids in the map

  PLANNER:
    collision_threshold: 0.20       # forward move distance under which we consider there's a collision (in meters)
    min_obs_dilation_selem_radius: 1    # radius (in cells) of obstacle dilation structuring element
    obs_dilation_selem_radius: 3    # radius (in cells) of obstacle dilation structuring element
    goal_dilation_selem_radius: 10  # radius (in cells) of goal dilation structuring element
    use_dilation_for_stg: False      # use dilated goals for estimating short-term goals - or just reaching
    map_downsample_factor: 1            # optional downsampling of traversible and goal map before fmm distance call (1 for no downsampling, 2 for halving resolution)
    map_update_frequency: 1             # compute fmm distance map every n steps 
    step_size: 5                    # maximum distance of the short-term goal selected by the planner
    discrete_actions: True         # discrete motion planner output space or not
    planner_type: "old"             # ("old", "new") where "new" is the latest one being used for spot in real world

  SUPERGLUE:
    max_keypoints: 1024
    keypoint_threshold: 0.005
    nms_radius: 4
    superglue_model: indoor           # or outdoor
    sinkhorn_iterations: 20
    match_threshold: 0.2
    score_function: confidence_sum    # or match_count
    score_thresh_image: 24.5  # real-world experiments used 6.0
    score_thresh_lang: 0.24
    match_projection_threshold: 0.2   # confidence must be at least this high to project as goal point.
    goto_past_pose: False
    batching: False

  DETIC:
    config_file: Detic/configs/Detic_LCOCOI21k_CLIP_SwinB_896b32_4x_ft4x_max-size.yaml
    vocabulary: custom
    custom_vocabulary: chair,sofa,bed,toilet,potted_plant,tv_monitor
    confidence_threshold: 0.2
    weights: Detic/models/Detic_LCOCOI21k_CLIP_SwinB_896b32_4x_ft4x_max-size.pth
    augment_mask_with_box: True

EVAL_VECTORIZED:
  simulator_gpu_ids: [1, 2, 3, 4, 5, 6, 7] # IDs of GPUs to use for vectorized environments
  specific_episodes: 0      # 1: eval on specific episodes (for debugging), 0: eval on split normally
  goal_on_same_floor: 0     # 1: restrict to episodes with a goal on the same floor as the starting position
  split: val_seen                # eval split
  num_episodes_per_env: 100 # number of eval episodes per environment
  record_videos: 0          # 1: record videos from printed images, 0: don't
  record_planner_videos: 0  # 1: record planner videos (if record videos), 0: don't
