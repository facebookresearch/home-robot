task_name: corl_experiment
action_idx: -1
load: False
max_actions: 6
split: assets/corl_experiments/combined_split.yaml
datadir: ../../datasets/corl_experiment/
template: "*/*.h5"

num_pts: 8000
orientation_type: "quaternion"  # change orientation_dim when you change this
learning_rate: 1e-4
lambda_weight_l2: 0.00001
optim: adam
multi_step: True
num_heads: 1
crop_size: 0.1
query_radius: 0.16
k: 3                          # will change per task, read from task_information.yaml
lang_max_seq_len: 77
clip_model: "ViT-B/32"
max_iter: 20
dry_run: False
validate: False
data_augmentation: True
source: "stretch"
wandb: False
debug: False

dims:
  proprio_in: 8
  proprio_out: 64
  image_in: 4
  lang_emb_out: 512
  position: 3
  orientation: 4
  # rgb_out:

handover_weights:
  position: 1e-1
  orientation: 1e-2
  gripper: 1e-3

weights:
  position: 1.0
  orientation: 1e-3
  gripper: 1e-3

model:
  sa1_mlp: [7, 64, 128]
  sa2_mlp: [131, 128, 256]
  sa3_mlp: [259, 256,512]
  proprio_mlp: [64, 256, 512]
  lang_mlp: [512, 512, 512]
  time_mlp: [6, 256, 512]
  pre_process_mlp: [2048, 1024, 1024, 512, 512]
  post_process_mlp: [512, 512, 256, 256, 128, 64]
  gru_dim: 512

regression_head:
  final_dim: 64
  pos_mlp: [256, 128, 64]
  ori_mlp: [256, 128, 64]
  gripper_mlp: [1536, 512, 64]
  pos_in_channels: 3

per_action_cmd: False
gru_hidden_dim: 512
gru_hidden_layers: 2
use_mdn: False
skill_to_action_file: configs/per_cmd_language.yaml
