{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"/home/xiaohan/accel-cortex/\"\n",
    "\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# with open(root_path + \"debug_svm.pkl\", \"rb\") as f:\n",
    "#     svm = pickle.load(f)\n",
    "\n",
    "\n",
    "# observations = svm.observations\n",
    "# with open(root_path + \"annotation.pkl\", \"rb\") as f:\n",
    "#     annotation = pickle.load(f)\n",
    "with open(root_path + \"stretch_output_2024-03-13_15-23-13.pkl\", \"rb\") as f:\n",
    "    obs_history = pickle.load(f)\n",
    "\n",
    "# print(annotation[\"task\"])\n",
    "# key_frames = []\n",
    "# key_obs = []\n",
    "# for idx, obs in enumerate(observations):\n",
    "#     perceived_ids = np.unique(obs.obs.task_observations[\"gt_instance_ids\"])\n",
    "#     for target_id in annotation[\"object_ids\"]:\n",
    "#         if (target_id + 1) in perceived_ids:\n",
    "#             print(\"target observation found\")\n",
    "#             key_frames.append(obs)\n",
    "#             key_obs.append(obs_history[idx])\n",
    "# obs = key_frames[-1]\n",
    "key_obs = obs_history[\"obs\"]\n",
    "obs = key_obs[-1]\n",
    "\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import imageio\n",
    "import yaml\n",
    "from PIL import Image\n",
    "\n",
    "from home_robot.agent.multitask import get_parameters\n",
    "from home_robot.mapping.voxel import (\n",
    "    SparseVoxelMap,\n",
    "    SparseVoxelMapNavigationSpace,\n",
    "    plan_to_frontier,\n",
    ")\n",
    "from home_robot.perception import create_semantic_sensor\n",
    "from home_robot.perception.encoders import get_encoder\n",
    "\n",
    "# image_array = np.array(obs.obs.rgb, dtype=np.uint8)\n",
    "# print(image_array.shape)\n",
    "# # image_array = image_array[..., ::-1]\n",
    "# image = Image.fromarray(image_array)\n",
    "\n",
    "\n",
    "parameters = yaml.safe_load(\n",
    "    Path(\"/home/xiaohan/home-robot/src/home_robot_sim/configs/gpt4v.yaml\").read_text()\n",
    ")\n",
    "config, semantic_sensor = create_semantic_sensor()\n",
    "semantic_sensor\n",
    "\n",
    "# parameters = get_parameters(cfg.agent_parameters)\n",
    "encoder = get_encoder(parameters[\"encoder\"], parameters[\"encoder_args\"])\n",
    "\n",
    "voxel_map = SparseVoxelMap(\n",
    "    resolution=parameters[\"voxel_size\"],\n",
    "    local_radius=parameters[\"local_radius\"],\n",
    "    obs_min_height=parameters[\"obs_min_height\"],\n",
    "    obs_max_height=parameters[\"obs_max_height\"],\n",
    "    min_depth=parameters[\"min_depth\"],\n",
    "    max_depth=parameters[\"max_depth\"],\n",
    "    pad_obstacles=parameters[\"pad_obstacles\"],\n",
    "    add_local_radius_points=parameters.get(\"add_local_radius_points\", True),\n",
    "    remove_visited_from_obstacles=parameters.get(\n",
    "        \"remove_visited_from_obstacles\", False\n",
    "    ),\n",
    "    obs_min_density=parameters[\"obs_min_density\"],\n",
    "    smooth_kernel_size=parameters[\"smooth_kernel_size\"],\n",
    "    encoder=encoder,\n",
    "    use_median_filter=parameters.get(\"use_median_filter\", False),\n",
    "    median_filter_size=parameters.get(\"median_filter_size\", 5),\n",
    "    median_filter_max_error=parameters.get(\"median_filter_max_error\", 0.01),\n",
    "    use_derivative_filter=parameters.get(\"use_derivative_filter\", False),\n",
    "    derivative_filter_threshold=parameters.get(\"derivative_filter_threshold\", 0.5),\n",
    "    instance_memory_kwargs={\n",
    "        \"min_pixels_for_instance_view\": parameters.get(\n",
    "            \"min_pixels_for_instance_view\", 100\n",
    "        ),\n",
    "        \"min_instance_thickness\": parameters.get(\"min_instance_thickness\", 0.05),\n",
    "        \"min_instance_vol\": parameters.get(\"min_instance_vol\", 1e-6),\n",
    "        \"max_instance_vol\": parameters.get(\"max_instance_vol\", 10.0),\n",
    "        \"min_instance_height\": parameters.get(\"min_instance_height\", 0.1),\n",
    "        \"max_instance_height\": parameters.get(\"max_instance_height\", 1.8),\n",
    "        \"open_vocab_cat_map_file\": parameters.get(\"open_vocab_cat_map_file\", None),    \n",
    "    },\n",
    ")\n",
    "\n",
    "voxel_map.reset()\n",
    "# key_obs = [key_obs[5]]\n",
    "for idx, obs in enumerate(key_obs):\n",
    "\n",
    "    image_array = np.array(obs.rgb, dtype=np.uint8)\n",
    "    # print(image_array.shape)\n",
    "    # # image_array = image_array[..., ::-1]\n",
    "    image = Image.fromarray(image_array)\n",
    "    image.show()\n",
    "\n",
    "    obs = semantic_sensor.predict(obs)\n",
    "    voxel_map.add_obs(obs)\n",
    "\n",
    "voxel_map.show(\n",
    "    instances=True,\n",
    "    height=1000,\n",
    "    boxes_plot_together=False,\n",
    "    backend=\"pytorch3d\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voxel_map.get_instances()[3]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "home-robot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
