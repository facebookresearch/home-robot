{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# Copyright (c) Meta Platforms, Inc. and affiliates.\n",
    "#\n",
    "# This source code is licensed under the MIT license found in the\n",
    "# LICENSE file in the root directory of this source tree.\n",
    "import argparse\n",
    "import dataclasses\n",
    "import sys\n",
    "import timeit\n",
    "from typing import Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scannet_dataset import ScanNetDataset\n",
    "# from referit3d_data import ReferIt3dDataConfig\n",
    "# from scanrefer_data import ScanReferDataConfig\n",
    "from pytorch3d.io import IO\n",
    "from pytorch3d.structures import Pointclouds\n",
    "from home_robot.datasets.scannet import ScanNetDataset, ReferIt3dDataConfig, ScanReferDataConfig, NUM_CLASSES_LONG\n",
    "data = ScanNetDataset(\n",
    "    root_dir = '/private/home/ssax/home-robot/src/home_robot/home_robot/datasets/scannet/data',\n",
    "    frame_skip = 180,\n",
    "    n_classes=NUM_CLASSES_LONG,\n",
    "    # n_classes=50,\n",
    "    referit3d_config = ReferIt3dDataConfig(),\n",
    "    scanrefer_config = ScanReferDataConfig(),\n",
    ")\n",
    "\n",
    "# Load specific scene\n",
    "# idx = data.scene_list.index(\"scene0192_00\") #'scene0000_00'\n",
    "idx = 0\n",
    "print(f\"Loaded images of (h: {data.height}, w: {data.width}) - resized from ({data.DEFAULT_HEIGHT},{data.DEFAULT_WIDTH})\")\n",
    "scene_obs = data.__getitem__(idx, show_progress=True)\n",
    "\n",
    "# Load GT mesh\n",
    "from pytorch3d.io import IO, load_obj, load_ply\n",
    "scene_id = scene_obs['scan_name']\n",
    "print(\"Loading GT mesh for\", scene_id)\n",
    "# verts = load_ply(data.root_dir / f'scans/{scene_id}/{scene_id}_vh_clean.ply')\n",
    "pc = IO().load_pointcloud(data.root_dir / f'scans/{scene_id}/{scene_id}_vh_clean.ply')\n",
    "verts = pc.points_packed()\n",
    "aligned_verts = torch.cat([verts, torch.ones_like(verts[:,:1])], dim=-1) @ scene_obs['axis_align_mats'][0].T\n",
    "pointcloud_aligned = Pointclouds(points=aligned_verts[...,:3].unsqueeze(0), features=pc.features_packed().unsqueeze(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[:10]\n",
    "scene_obs['ref_expr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize referring expression\n",
    "# Title: Query\n",
    "# Trace: Pointcloud \n",
    "# Trace: GT bbox\n",
    "# Trace: Distractors of same class\n",
    "selected = scene_obs['box_target_ids'] == 39\n",
    "id_to_name = dict(zip(data.METAINFO['CLASS_IDS'], data.METAINFO['CLASS_NAMES']))\n",
    "id_to_name[scene_obs['box_classes'][selected].item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K = scene_obs['intrinsics'][0][:3,:3]\n",
    "# depth = scene_obs['depths'][0].squeeze().unsqueeze(0).unsqueeze(1)\n",
    "# valid_depth  = (0.1 < depth) & (depth < 4.0)\n",
    "\n",
    "# xyz = unproject_masked_depth_to_xyz_coordinates(\n",
    "#     depth = depth,\n",
    "#     mask  = ~valid_depth,\n",
    "#     pose  = torch.eye(4).unsqueeze(0),\n",
    "#     inv_intrinsics = torch.linalg.inv(K).unsqueeze(0),\n",
    "# )\n",
    "# rgb = scene_obs['images'][0].reshape(-1,3)[valid_depth.flatten()]\n",
    "# print(scene_obs['image_paths'][0])\n",
    "# print(f\"Proportion depth valid: {float(valid_depth.float().mean())}\")\n",
    "# print(f\"Depth min + max: {float(depth.flatten()[valid_depth.flatten()].min())}, {float(depth.flatten()[valid_depth.flatten()].max())}\")\n",
    "# print(\"These are the mins-maxes along each world axis. They should be in meters:\")\n",
    "# for i in range(3):\n",
    "#     print(f\"  {i}: ({float(xyz[:,i].min())}, {float(xyz[:,i].max())})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(scene_obs['depths'][0])\n",
    "plt.show()\n",
    "plt.imshow(scene_obs['images'][0])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from home_robot.perception.detection.detic.detic_perception import DeticPerception\n",
    "segmenter = DeticPerception(\n",
    "        config_file=None,\n",
    "        vocabulary=\"coco\",\n",
    "        custom_vocabulary=\"\",\n",
    "        checkpoint_file=None,\n",
    "        sem_gpu_id=0,\n",
    "        # verbose: bool = False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(res['semantic_frame'])\n",
    "plt.show()\n",
    "plt.imshow(scene_obs['instance_map'][-1] == 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -> SparseVoxelMapWithInstanceViews.show(backend='pytorch3d')\n",
    "\n",
    "# Plot GT scene\n",
    "from home_robot.utils.bboxes_3d import BBoxes3D, join_boxes_as_scene, join_boxes_as_batch\n",
    "from home_robot.utils.bboxes_3d_plotly import plot_scene_with_bboxes\n",
    "from pytorch3d.vis.plotly_vis import AxisArgs\n",
    "from pytorch3d.structures import Pointclouds\n",
    "import seaborn as sns\n",
    "\n",
    "colors = torch.tensor(sns.color_palette(\"husl\", len(scene_obs['boxes_aligned'])))\n",
    "gt_boxes = BBoxes3D(\n",
    "    bounds = [scene_obs['boxes_aligned']],\n",
    "    # features = [colors[0].unsqueeze(0).expand(27,3)],\n",
    "    features = [colors],\n",
    "    names = [scene_obs['box_classes'].unsqueeze(-1)]\n",
    ")\n",
    "\n",
    "fig = plot_scene_with_bboxes(\n",
    "    plots = { f\"{scene_id}\": { \n",
    "\n",
    "                                \"GT boxes\": gt_boxes,\n",
    "                                \"GT points\": pointcloud_aligned,\n",
    "                                # \"cameras\": cameras,\n",
    "                            }\n",
    "    },\n",
    "    xaxis={\"backgroundcolor\":\"rgb(200, 200, 230)\"},\n",
    "    yaxis={\"backgroundcolor\":\"rgb(230, 200, 200)\"},\n",
    "    zaxis={\"backgroundcolor\":\"rgb(200, 230, 200)\"}, \n",
    "    axis_args=AxisArgs(showgrid=True),\n",
    "    pointcloud_marker_size=3,\n",
    "    pointcloud_max_points=30_000,\n",
    "    boxes_wireframe_width=3,\n",
    "    boxes_add_cross_face_bars=False,\n",
    "    # boxes_name_int_to_display_name_dict = dict(zip([int(i) for i in data.METAINFO['seg_valid_class_ids']], data.METAINFO['classes'])),\n",
    "    boxes_name_int_to_display_name_dict = dict(zip(data.METAINFO['CLASS_IDS'], data.METAINFO['CLASS_NAMES'])),\n",
    "\n",
    "    boxes_plot_together=False,\n",
    "    height=1000,\n",
    "    # width=1000,\n",
    ")\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
