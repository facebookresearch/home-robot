{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# Copyright (c) Meta Platforms, Inc. and affiliates.\n",
    "#\n",
    "# This source code is licensed under the MIT license found in the\n",
    "# LICENSE file in the root directory of this source tree.\n",
    "import argparse\n",
    "import dataclasses\n",
    "import sys\n",
    "import timeit\n",
    "from typing import Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scannet_dataset import ScanNetDataset\n",
    "data = ScanNetDataset(\n",
    "    root_dir = '/private/home/ssax/home-robot/projects/eval_scannet/scannet',\n",
    "    frame_skip = 180,\n",
    ")\n",
    "\n",
    "# Load specific scene\n",
    "idx = data.scene_list.index(\"scene0192_00\") #'scene0000_00'\n",
    "# idx = 0\n",
    "print(f\"Loaded images of (h: {data.height}, w: {data.width}) - resized from ({data.DEFAULT_HEIGHT},{data.DEFAULT_WIDTH})\")\n",
    "scene_obs = data.__getitem__(idx, show_progress=True)\n",
    "\n",
    "# Load GT mesh\n",
    "from pytorch3d.io import IO, load_obj, load_ply\n",
    "scene_id = scene_obs['scan_name']\n",
    "print(\"Loading GT mesh for\", scene_id)\n",
    "verts = load_ply(f'/private/home/ssax/home-robot/projects/eval_scannet/scannet/scans/{scene_id}/{scene_id}_vh_clean.ply')\n",
    "aligned_verts = torch.cat([verts[0], torch.ones_like(verts[0][:,:1])], dim=-1) @ scene_obs['axis_align_mats'][0].T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K = scene_obs['intrinsics'][0][:3,:3]\n",
    "# depth = scene_obs['depths'][0].squeeze().unsqueeze(0).unsqueeze(1)\n",
    "# valid_depth  = (0.1 < depth) & (depth < 4.0)\n",
    "\n",
    "# xyz = unproject_masked_depth_to_xyz_coordinates(\n",
    "#     depth = depth,\n",
    "#     mask  = ~valid_depth,\n",
    "#     pose  = torch.eye(4).unsqueeze(0),\n",
    "#     inv_intrinsics = torch.linalg.inv(K).unsqueeze(0),\n",
    "# )\n",
    "# rgb = scene_obs['images'][0].reshape(-1,3)[valid_depth.flatten()]\n",
    "# print(scene_obs['image_paths'][0])\n",
    "# print(f\"Proportion depth valid: {float(valid_depth.float().mean())}\")\n",
    "# print(f\"Depth min + max: {float(depth.flatten()[valid_depth.flatten()].min())}, {float(depth.flatten()[valid_depth.flatten()].max())}\")\n",
    "# print(\"These are the mins-maxes along each world axis. They should be in meters:\")\n",
    "# for i in range(3):\n",
    "#     print(f\"  {i}: ({float(xyz[:,i].min())}, {float(xyz[:,i].max())})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(scene_obs['depths'][0])\n",
    "plt.show()\n",
    "plt.imshow(scene_obs['images'][0])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from home_robot.perception.detection.detic.detic_perception import DeticPerception\n",
    "segmenter = DeticPerception(\n",
    "        config_file=None,\n",
    "        vocabulary=\"coco\",\n",
    "        custom_vocabulary=\"\",\n",
    "        checkpoint_file=None,\n",
    "        sem_gpu_id=0,\n",
    "        # verbose: bool = False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(res['semantic_frame'])\n",
    "plt.show()\n",
    "plt.imshow(scene_obs['instance_map'][-1] == 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -> SparseVoxelMapWithInstanceViews.show(backend='pytorch3d')\n",
    "\n",
    "# Plot GT scene\n",
    "from home_robot.utils.bboxes_3d import BBoxes3D, join_boxes_as_scene, join_boxes_as_batch\n",
    "from home_robot.utils.bboxes_3d_plotly import plot_scene_with_bboxes\n",
    "from pytorch3d.vis.plotly_vis import AxisArgs\n",
    "from pytorch3d.structures import Pointclouds\n",
    "import seaborn as sns\n",
    "\n",
    "colors = torch.tensor(sns.color_palette(\"husl\", len(scene_obs['boxes_aligned'])))\n",
    "gt_boxes = BBoxes3D(\n",
    "    bounds = [scene_obs['boxes_aligned']],\n",
    "    # features = [colors[0].unsqueeze(0).expand(27,3)],\n",
    "    features = [colors],\n",
    "    names = [scene_obs['box_classes'].unsqueeze(-1)]\n",
    ")\n",
    "\n",
    "fig = plot_scene_with_bboxes(\n",
    "    plots = { f\"{scene_id}\": { \n",
    "                                \"Points\": svm.global_voxel_grid._pcl,\n",
    "                                # \"Boxes\": join_boxes_as_scene(svm.instance_bboxes3d),\n",
    "                                \"All boxes\": global_boxes,\n",
    "                                \"Global boxes\": global_boxes,\n",
    "                                \"GT boxes\": gt_boxes,\n",
    "                                \"GT points\": Pointclouds(points=[aligned_verts[:, :3]]),\n",
    "                                # \"cameras\": cameras,\n",
    "                            }\n",
    "    },\n",
    "    xaxis={\"backgroundcolor\":\"rgb(200, 200, 230)\"},\n",
    "    yaxis={\"backgroundcolor\":\"rgb(230, 200, 200)\"},\n",
    "    zaxis={\"backgroundcolor\":\"rgb(200, 230, 200)\"}, \n",
    "    axis_args=AxisArgs(showgrid=True),\n",
    "    pointcloud_marker_size=3,\n",
    "    pointcloud_max_points=30_000,\n",
    "    boxes_wireframe_width=3,\n",
    "    boxes_add_cross_face_bars=False,\n",
    "    boxes_name_int_to_display_name_dict = dict(zip([int(i) for i in data.METAINFO['seg_valid_class_ids']], data.METAINFO['classes'])),\n",
    "    boxes_plot_together=False,\n",
    "    height=1000,\n",
    "    # width=1000,\n",
    ")\n",
    "fig"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
